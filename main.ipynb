{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from func_modules import ControllerGraph\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Clean the dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We read the datasets from the `csv` files, then we clean them according to the required steps in the `readme` file describing the homework:\n",
    "- Space at the end and slash at the end are removed in the names from `hero_network`.\n",
    "- Rows inducing loops are removed.\n",
    "- Solve the Spider-Man problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the dataframes\n",
    "edges = pd.read_csv(os.path.join('data', 'edges.csv'))\n",
    "hero_network = pd.read_csv(os.path.join('data', 'hero-network.csv'))\n",
    "nodes = pd.read_csv(os.path.join('data', 'nodes.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This simple Regex substitution solves slash and space problem in hero network\n",
    "hero_network['hero1'] = hero_network.hero1.str.replace(r'/$|\\s$', '', regex=True)\n",
    "hero_network['hero2'] = hero_network.hero2.str.replace(r'/$|\\s$', '', regex=True)\n",
    "\n",
    "# Remove rows inducing loops in the graph\n",
    "hero_network = hero_network[~(hero_network.hero1 == hero_network.hero2)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fix Peter Parker name\n",
    "hero_network.loc[hero_network.hero1 == 'SPIDER-MAN/PETER PAR', 'hero1'] = 'SPIDER-MAN/PETER PARKER'\n",
    "hero_network.loc[hero_network.hero2 == 'SPIDER-MAN/PETER PAR', 'hero2'] = 'SPIDER-MAN/PETER PARKER'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Build the graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's build the first graph, the one from `hero_network`, undirected and weighted, with weights decreasing as the number of common appearances in comics increases. The approach chosen is similar to an idf measure, with the weight being given by $\\frac{1}{\\log(x)+1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count appearances of hero 1 and hero 2 (ordered)\n",
    "hero_counts = hero_network.value_counts()\n",
    "# Group with frozenset, this way we get count of appearances without taking into consideration the order\n",
    "hero_counts = hero_counts.groupby(lambda x: frozenset(x)).sum()\n",
    "# Move frozenset from index to column\n",
    "hero_counts = hero_counts.reset_index(name = 'count')\n",
    "\n",
    "# List constructor onto frozenset (because pd.Series requires order) and then pd.Series to split the lists and get two different series\n",
    "# (resulting in a DataFrame). Then concatenate count Series with these other two we have obtained. This is close to the final dataset we need.\n",
    "hero_counts = pd.concat([hero_counts['index'].apply(list).apply(pd.Series), hero_counts['count']], axis = 1)\n",
    "\n",
    "hero_counts['weight'] = 1/(1+np.log(hero_counts['count'])) # Compute weights with something quite similar to idf weights\n",
    "hero_counts.drop('count', axis = 1, inplace = True) # Drop count column, we don't need that anymore\n",
    "hero_counts.rename({0: 'hero1', 1:'hero2'}, axis = 1, inplace = True) # Rename for tidiness\n",
    "\n",
    "# Build the undirected graph from edgelist + weight attribute\n",
    "hero_graph = nx.from_pandas_edgelist(hero_counts, source='hero1', target='hero2', edge_attr='weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now we build the second graph, the one from edges and considering the node type. For this we need to use `nodes` and `edges`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hero_comics_graph = nx.from_pandas_edgelist(edges, source='hero', target='comic')\n",
    "nodes_attr_dict = nodes.set_index('node').to_dict(orient='index')\n",
    "nx.set_node_attributes(hero_comics_graph, nodes_attr_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We instantiate the controller object which is needed to call the functionalities."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "controller = ControllerGraph(edges) # Edges is passed for the top N heroes list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "b0b56bc0-d8dc-4e41-9b2e-d4570eddbc76",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functionality 1: Explaining and Visualizing\n",
    "### Heroes graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7333d6ce",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Lorem ipsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc29890-9b41-411c-a8ac-f952471af7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_nodes,number_of_collaborations,\\\n",
    "    heroes_in_comic,density,networks_degree_distribution,\\\n",
    "    average_degree,network_hubs,network = controller.functionality(1, hero_graph, graph_type= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95cb205-b48e-4b8d-8b33-4a97e1ed4042",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Table containing the following general information about the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db644a82-656e-495e-8881-5eb268d4e82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = [['Number of nodes in the network', number_of_nodes], ['Density of the network', density],['Average degree of the network',average_degree],[\"The network is\", network]]\n",
    "print(tabulate(table, tablefmt='grid',numalign=\"right\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f57fc6-d124-46e1-a46b-f4f340412d00",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Table that lists the network's hubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7585b3-0608-46f8-9fee-bec3ccc4bf79",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "table=list(network_hubs)\n",
    "tab=[[i,table[i]] for i in range(len(table))]\n",
    "#tab\n",
    "print(tabulate(tab,tablefmt='github',headers=[\"ID\",\"Network's hubs\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501ef655-91dc-413a-b782-b75601162940",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Plot depicting the number of collaborations of each hero in descending order\n",
    "Lorem ipsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb407b3-b073-455d-9cef-ada0137a79fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_50=dict(number_of_collaborations.most_common(50))\n",
    "plt.gcf().set_size_inches((12, 8))\n",
    "plt.tick_params(axis='x', labelrotation=90)\n",
    "plt.title(\"Number of collaborations of each hero\")\n",
    "plt.xlabel(\"Heroes\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.bar(top_50.keys(),top_50.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71495aa3-9027-4ffd-8f74-54a5c0c9f127",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Plot depicting the degree distribution of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badaabf9-d8df-4c00-b3e4-24461002d216",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gcf().set_size_inches((12, 8))\n",
    "plt.title(\"The network's degree distribution\")\n",
    "plt.plot(networks_degree_distribution)\n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780e8197-1596-4b34-8e0d-970d160b41a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Heroes and comics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ba0ce4-f511-45d7-8b78-9a2ce42e9a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_nodes,number_of_collaborations,\\\n",
    "    heroes_in_comic,density,networks_degree_distribution,\\\n",
    "    average_degree,network_hubs,average_clustering = controller.functionality(1, hero_comics_graph, graph_type= 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20062c1c-299a-4f46-b7ff-7a9d3a3bcf2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Table containing the following general information about the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6b431c-443a-437c-a9ac-f02000579062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table = [['Number of nodes in the network', number_of_nodes], ['Density of the network', density],['Average degree of the network',average_degree],[\"Average clustering coefficient\",average_clustering]]\n",
    "print(tabulate(table, tablefmt='grid',numalign=\"right\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f19ab0-bd57-481f-b18d-e2e68af8026f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Table that lists the network's hubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d608ce90-25ce-4b86-8652-4b341d8c78b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "table=list(network_hubs)\n",
    "tab=[[i,table[i]] for i in range(len(table))]\n",
    "#tab\n",
    "print(tabulate(tab,tablefmt='github',headers=[\"ID\",\"Network's hubs\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a346216-ab83-427f-97e8-92240a27a2e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Plot depicting the number of heroes who appeared in each comic, sorted in descending order\n",
    "Lorem ipsum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c35063-1dcc-404f-a9b9-2ad70ac994d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_50 = dict(sorted(heroes_in_comic.items(), key = lambda x: x[1], reverse = True)[:51])\n",
    "plt.gcf().set_size_inches((12, 8))\n",
    "plt.tick_params(axis='x', labelrotation=90)\n",
    "plt.title(\"Number of heroes who appeared in each comic\")\n",
    "plt.xlabel(\"Comics\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.bar(top_50.keys(),top_50.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214fc554-42c8-4b3d-8037-0d35ee2ecf8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Plot depicting the degree distribution of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a828a125-3ad7-49f0-a2a1-899a73ee132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gcf().set_size_inches((12, 8))\n",
    "plt.title(\"The network's degree distribution\")\n",
    "plt.plot(networks_degree_distribution)\n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a21717-493e-4f44-a120-f5ef9d8ddf1b",
   "metadata": {},
   "source": [
    "## Functionality 2: explaining and visualizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a5bf36-70fb-4d05-af02-c9995cd2bb37",
   "metadata": {},
   "source": [
    "We call `func2`, which you can inspect in the `functionality_2.py` module in the `func_modules` package, to take the values of the matric chosen by the user on the entire graph (or subgraph if the user chooses the number N of `top_heroes`) and on the hero selected. To take this values we use some functions imported by `networkx` like `nx.betweenness_centrality()`,  `nx.pagerank_numpy()`, `nx.closeness_centrality()` and `nx.degree_centrality()`.\n",
    "Then we calculate the average of the requested centrality measure for all of the network's nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d856001-568a-4d6c-8145-ab14228aed4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The metric values calculated on the graph and on the selected hero\n",
    "metric_values, hero_metric_value = controller.functionality(2,hero_graph, hero = 'CAPTAIN AMERICA', metric = 'betweenness_centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838a71d3-834f-4e57-ae36-fafe96e70550",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_centrality = np.array(list(metric_values.values())).mean() #The average of the requested centrality measure for all of the network's nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b838863b-4f54-4276-8ac4-654ac11eb003",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = [['Avarage of the centrality measure', mean_centrality], ['Centrality measure for the given hero', hero_metric_value]]\n",
    "print(tabulate(table, tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96185603-f2a6-4cb6-88c9-f7b766c80823",
   "metadata": {},
   "source": [
    "- The ***betweenness centrality*** of a node measures the extent to which the node lies on the shortest paths between other nodes. A high betweenness centrality value means that the node is located on many shortest paths and, therefore, has a *central position* within the graph. On the other hand, a low betweenness centrality value indicates that the node is not on many shortest paths and, therefore, has a *less central position* within the graph.\n",
    "\n",
    "- The ***PageRank*** of a node measures the importance of the node within the graph, with higher values indicating more important nodes. A high PageRank value means that the node is more likely to be visited by a random walker and, therefore, has a *more central position* within the graph. On the other hand, a low PageRank value indicates that the node is less likely to be visited and, therefore, has a *less central position* within the graph.\n",
    "\n",
    "- The ***closeness centrality*** of a node measures the average distance from the node to all other nodes in the graph. A high closeness centrality value means that the node is close to many other nodes and, therefore, has a *central position* within the graph. On the other hand, a low closeness centrality value indicates that the node is far from many other nodes and, therefore, has a *less central position* within the graph.\n",
    "\n",
    "- The ***degree centrality*** of a node measures the number of edges incident to the node. A high degree centrality value means that the node has many connections to other nodes and, therefore, has a *central position* within the graph. On the other hand, a low degree centrality value indicates that the node has few connections to other nodes and, therefore, has a *less central position* within the graph.\n",
    "\n",
    "If a user has a high *betweenness centrality* value, this means that they are located on many shortest paths within the graph and are therefore considered to be a key connector. If the user has a low *betweenness centrality* value but a high *PageRank* value, this may mean that they are not on many shortest paths but are still considered to be an important node within the graph due to the high number of visits they receive. Similarly, if the user has a high *closeness centrality* value, this means that they are close to many other nodes in the graph and are therefore considered to be a central node. If the user has a high *degree centrality* value, this means that they have many connections to other nodes and are therefore considered to be a central node within the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Functionality 3: explaining and visualizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For the third functionality we are asked to build a function which, given the bipartite graph with heroes and comics, returns the shortest walk passing through a given set of heroes in order (the order of first visit is what matters), with the endpoints of the walk also given.\n",
    "\n",
    "The straightforward implementation we can think of here is simply repeatedly using Breadth-First Search to get from one node to the next one in the sequence, exploiting the fact that we [know that](http://aris.me/contents/teaching/data-mining-ds-2019/resources/CLRS-graphs,bfs,dfs.pdf) exploring with BFS we get the shortest path. The ordered sequence of shortest paths is bound to be the shortest walk.\n",
    "\n",
    "Therefore, `func_3`, which you can inspect in the `functionalities_34.py` module in the `func_modules` package, is simply a manual implementation of Breadth-First Search with a few tweaks. More specifically:\n",
    "\n",
    "- As we have already said, BFS is the core of the functionality, but not the functionality as a whole. BFS is repeated, with the current target then becoming the source of the following iteration. The iteration starts with the first endpoint as the first source node and ends with the second endpoint as the last target node.\n",
    "- Of course, we don't just need to explore the nodes reachable from a source, but we also need to store the path from the source to the visited node, each time. This is actually quite simple to do, and it can be done by simply storing in the BFS queue not only the identifier of the visited node, but also the path with which we can reach it from the source. This allows to have some _persistent memory_ in the process as more levels are explored. When the current target is reached, the `walk` list is extended with the shortest path found in the current iteration with BFS.\n",
    "- We need to take into consideration the order of first visit. This simply amounts to hardcode the fact that the BFS should not visit nodes which follow the target one (for the current iteration) in the sequence.\n",
    "- If at any iteration of our _repeated BFS_ the current target node cannot be reached with BFS, then the whole execution has to halt, print a proper warning message and return an empty list (the empty walk). This can be done by adding a boolean flag which is set to True only when the current target node is found at the current iteration.\n",
    "\n",
    "Now we call the functionality through the `functionality` method of the controller, considering the whole graph. `seq` is the sequence of heroes we have to pass through, `endpoints` is the tuple giving the starting and terminal endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_walk = controller.functionality(3, hero_comics_graph,\n",
    "                         seq = ['ABOMINATION/EMIL BLO', 'ANCIENT ONE', 'IRON MAN/TONY STARK', 'SPIDER-MAN/PETER PARKER'],\n",
    "                         endpoints=('CAPTAIN AMERICA', 'CAPTAIN MARVEL/CAPTA'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now we visualize the result in a proper way. We make different calls to the NetworkX plotting functions (which use the matplotlib engine and are thus compatible with the usual framework) in order to build a complex visualization. For the plot we consider only the nodes and the edges in the walk, with the edges between them not present in the walk which are anyway drawn, but with a very low value of the `alpha` channel and with limited width.\n",
    "\n",
    "As required, labels are added to the edges in order to highlight the ordering, which is anyway clear even without those. Since the graph is at this point planar, we can have a relatively clear visualization with the `planar_layout` function for the dictionary of positions. The hero nodes are blue and the comic nodes are red, and this difference in color highlights the fact that the graph is bipartite (a red always follows a blue, and vice-versa). It was also requested to print the comic nodes in the shortest walk: those are printed in the upper left corner of the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples_walk = list()\n",
    "dict_labels_edge = dict()\n",
    "for idx in range(len(shortest_walk)-1):  # Build list of edges in the walk and build dictionary of order indexes for edges\n",
    "    tuples_walk.append((shortest_walk[idx], shortest_walk[idx+1]))\n",
    "    dict_labels_edge[(shortest_walk[idx], shortest_walk[idx+1])] = idx+1\n",
    "\n",
    "# Get subgraph to plot\n",
    "plot_graph = nx.subgraph_view(hero_comics_graph, filter_node=lambda x: x in shortest_walk,\n",
    "                              filter_edge = lambda x, y: (x, y) in tuples_walk or (y, x) in tuples_walk)\n",
    "plt.gcf().set_size_inches((12, 10)) # Change size of the plot\n",
    "\n",
    "dict_pos = nx.planar_layout(plot_graph) # Dictionary of positions\n",
    "nx.draw_networkx_edges(plot_graph, pos = dict_pos, width=5)  # Draw edges in the walk\n",
    "\n",
    "# Draw nodes with specific color, with labels (the names)\n",
    "nx.draw_networkx_nodes(plot_graph, pos = dict_pos,\n",
    "                       node_color = ['blue' if plot_graph.nodes[x]['type'] == 'hero' else 'red' for x in plot_graph.nodes])\n",
    "nx.draw_networkx_labels(plot_graph, pos = dict_pos, horizontalalignment='left', verticalalignment='bottom')\n",
    "\n",
    "# Draw edges with specific labels (the index highlighting the ordering)\n",
    "nx.draw_networkx_edges(nx.subgraph_view(hero_comics_graph, filter_node=lambda x: x in shortest_walk),\n",
    "                       pos = dict_pos, alpha = 0.1)\n",
    "nx.draw_networkx_edge_labels(plot_graph, pos = dict_pos, edge_labels=dict_labels_edge, font_size=10)\n",
    "\n",
    "plt.margins(x = 0.09)  # Add some margin in order not to cut labels\n",
    "plt.text(-1.2, 0.45, s = 'Comics in shortest walk (red nodes): '+\n",
    "                         ', '.join([x for x in shortest_walk if hero_comics_graph.nodes[x]['type'] == 'comic']))\n",
    "plt.suptitle('Getting from Cap. America to Cap. Marvel saying \\'Hi\\' to some heroes', size = 20)\n",
    "plt.title('Notice that a comic (red nodes) always follows a hero (blue nodes), and viceversa. \\n'\n",
    "          'This is due to the fact that the graph with heroes and comics is bipartite.', pad = 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Functionality 4: Explaining and Visualizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The main idea here is exploiting the [max-flow min-cut theorem](https://en.wikipedia.org/wiki/Max-flow_min-cut_theorem) which allow us to link max-flow problems to min-cut problems. In other words we have to disconnect the source from the sink inducing a cut/a partition, and we need to do that with the minimum cost/cumulative weight possible, thus finding the s-t cut with the minimum capacity over the set of all the possible ones.\n",
    "\n",
    "Doing that is not trivial and requires some relatively advanced tools. First of all we need to build the residual graph, i.e. the graph representing the flow in the maximized scenario. In the original graph, the weight of an edge is its capacity, i.e. the maximum amount of flow it can carry. With the residual graph, we have a **directed** graph, since the flow has a direction: the residual capacity of each edge is given by $r_{i,j} = c_{i,j}-f_{i,j}$, with $c_{i,j}$ as the original capacity/the weight of the undirected edge between $i$ and $j$ and $f_{i,j}$ being the **directed** flow passing through the edge in the specific direction, which is negative if the flow goes backwards. It is trivial to notice, but I will stress it: $r_{i, j} \\neq r_{j,i}$. To give an example, $r_{i, j} = 0 \\rightarrow r_{j,i} \\geq c_{j,i} = c_{i, j}$\n",
    "\n",
    "For each original undirected edge we thus have two directed edges. Now, suppose that we can reach a node from the source only using edges with non-null residual capacity: we will not be able to reach the sink (otherwise we would have an augmenting path) and the nodes we reach are the ones which represent one of the two subsets induced by the minimum s-t cut, i.e. the one with minimum cost/capacity disconnecting source and sink. The edges we need to get a cut-set are the ones connecting these reachable nodes to the non-reachable ones.\n",
    "\n",
    "This is exactly what we are doing in our implementation:\n",
    "- We use [Edmonds-Karp](https://en.wikipedia.org/wiki/Edmonds–Karp_algorithm) (the [Ford-Fulkerson algorithm](https://en.wikipedia.org/wiki/Ford–Fulkerson_algorithm)) from NetworkX set of algorithms. This allows us to have the residual graph returned.\n",
    "- Once we have that, we perform Breadth-First Search from the source using only the edges with non-null residual capacity. The nodes we reach are the ones in the first subset induced by the minimum s-t cut.\n",
    "- Once we have the labels/the name of the nodes of the first subset, we simply cut each connection in the original graph with the others in the second. For that, we can use the `edge_boundary` function from NetworkX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_edges_lost, edges_lost, cut_graph = controller.functionality(4, hero_graph, 35,\n",
    "                                                                 hero_2='SPIDER-MAN/PETER PARKER', hero_1='IRON MAN/TONY STARK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now we visualize the output of the functionality: notice that we are considering only the top 35 heroes since otherwise it would be impossible to see anything clearly. The problem is that by taking the top 35 heroes the resulting graph of heroes (we are choosing that one since it is weighted) is complete: this means that in general the cut-set will always contain only edges adjacent to the source or the sink. It is just simple logic, jumping to a neighbour of source or sink for the cut produces a combinatorial explosion: instead of removing one edge in order to induce the cut from source to sink, we now have to remove $N-2$, with $N$ as the number of nodes. Apart from very strange distributions of the weights, this kind of situation induces s-t cut where the cut-set is adjacent to source or sink. The result is a cut $C(S, T)$ where $S = \\{s\\}$ or with $T = \\{t\\}$, with $s$ being the source and $t$ being the sink.\n",
    "\n",
    "Notice that we would have an identical situation also increasing the number of nodes (increasing the top heroes number). Considering the graph without filtering for top heroes allows for the smaller cut to have more than one vertex, but the idea remains the same.\n",
    "\n",
    "In order to visualize the min-cut s-t for the 35 heroes we chose not to plot two graphs - with and without the edges in the cut-set-, but only one highlighting the edges in the cut-set, which combines the two perspectives. The edges in the cut-set are shown in red, which is also the colour of source and sink. The rest of the edges are anyway shown, but with a lower alpha channel, which is anyway higher - relatively speaking - as the weight increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gcf().set_size_inches((12, 10)) # Increase size of plot\n",
    "plot_graph = cut_graph.copy() # Copy graph (without the edges in the cut-set) to avoid modifying in place\n",
    "plot_graph.add_edges_from(edges_lost) # Add edges which were lost (the one in the cut-set)\n",
    "\n",
    "dict_pos = nx.circular_layout(plot_graph) # Circular layout because it is more clear\n",
    "# Color source and sink\n",
    "color_node = ['red' if node == 'SPIDER-MAN/PETER PARKER' or node == 'IRON MAN/TONY STARK' else 'blue' for node in plot_graph.nodes]\n",
    "nx.draw_networkx_nodes(plot_graph, pos = dict_pos, node_size = 100, node_color=color_node) # Draw nodes\n",
    "# Draw labels\n",
    "nx.draw_networkx_labels(plot_graph, pos = dict_pos, font_size=6, font_family='helvetica', verticalalignment='bottom', font_weight='heavy')\n",
    "\n",
    "# Set color list, red for edges in cut-set, gray otherwise\n",
    "color_edges = ['red' if (edge in edges_lost or tuple(reversed(edge)) in edges_lost) else 'gray' for edge in plot_graph.edges]\n",
    "# Set alpha channel, a function of the weight, 1 for edges in the cut-set (which do not have weight attribute)\n",
    "alpha_edges = [x[2]/1.5 if x[2] else 1 for x in plot_graph.edges(data='weight')]\n",
    "# Draw the edges with the alpha and color info we have built\n",
    "nx.draw_networkx_edges(plot_graph, pos = dict_pos, alpha = alpha_edges, edge_color = color_edges)\n",
    "\n",
    "# Add some margins\n",
    "plt.margins(x=0.10)\n",
    "plt.suptitle('Minimum effort, maximum result: disconnecting Spider-Man from Iron Man', size = 20)\n",
    "plt.title(f'Removing the edges (n = {num_edges_lost}) which the sink is incident with induces the st-cut. \\n'\n",
    "          'This makes sense due to the fact that the graph is complete when considering\\n'\n",
    "          ' the top N heroes and anyway very dense in general.', pad = 12)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
