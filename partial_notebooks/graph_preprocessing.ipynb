{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clean the dataframes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We read the datasets from the `csv` files, then we clean them according to the required steps in the `readme` file describing the homework:\n",
    "- Space at the end and slash at the end are removed in the names from `hero_network`.\n",
    "- Rows inducing loops are removed.\n",
    "- Solve the Spider-Man problem."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read the dataframes\n",
    "edges = pd.read_csv(os.path.join('data', 'edges.csv'))\n",
    "hero_network = pd.read_csv(os.path.join('data', 'hero-network.csv'))\n",
    "nodes = pd.read_csv(os.path.join('data', 'nodes.csv'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# This simple Regex substitution solves slash and space problem in hero network\n",
    "hero_network['hero1'] = hero_network.hero1.str.replace(r'/$|\\s$', '', regex=True)\n",
    "hero_network['hero2'] = hero_network.hero2.str.replace(r'/$|\\s$', '', regex=True)\n",
    "\n",
    "# Remove rows inducing loops in the graph\n",
    "hero_network = hero_network[~(hero_network.hero1 == hero_network.hero2)].copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fix Peter Parker name\n",
    "hero_network.loc[hero_network.hero1 == 'SPIDER-MAN/PETER PAR', 'hero1'] = 'SPIDER-MAN/PETER PARKER'\n",
    "hero_network.loc[hero_network.hero2 == 'SPIDER-MAN/PETER PAR', 'hero2'] = 'SPIDER-MAN/PETER PARKER'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build the graphs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's build the first graph, the one from `hero_network`, undirected and weighted, with weights decreasing as the number of common appearances in comics increases. The approach chosen is similar to an idf measure, with the weight being given by $\\frac{1}{\\log(x)+1}$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Count appearances of hero 1 and hero 2 (ordered)\n",
    "hero_counts = hero_network.value_counts()\n",
    "# Group with frozenset, this way we get count of appearances without taking into consideration the order\n",
    "hero_counts = hero_counts.groupby(lambda x: frozenset(x)).sum()\n",
    "# Move frozenset from index to column\n",
    "hero_counts = hero_counts.reset_index(name = 'count')\n",
    "\n",
    "# List constructor onto frozenset (because pd.Series requires order) and then pd.Series to split the lists and get two different series\n",
    "# (resulting in a DataFrame). Then concatenate count Series with these other two we have obtained. This is close to the final dataset we need.\n",
    "hero_counts = pd.concat([hero_counts['index'].apply(list).apply(pd.Series), hero_counts['count']], axis = 1)\n",
    "\n",
    "hero_counts['weight'] = 1/(1+np.log(hero_counts['count'])) # Compute weights with something quite similar to idf weights\n",
    "hero_counts.drop('count', axis = 1, inplace = True) # Drop count column, we don't need that anymore\n",
    "hero_counts.rename({0: 'hero1', 1:'hero2'}, axis = 1, inplace = True) # Rename for tidiness\n",
    "\n",
    "# Build the undirected graph from edgelist + weight attribute\n",
    "hero_graph = nx.from_pandas_edgelist(hero_counts, source='hero1', target='hero2', edge_attr='weight')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we build the second graph, the one from edges and considering the node type. For this we need to use `nodes` and `edges`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hero_comics_graph = nx.from_pandas_edgelist(edges, source='hero', target='comic')\n",
    "nodes_attr_dict = nodes.set_index('node').to_dict(orient='index')\n",
    "nx.set_node_attributes(hero_comics_graph, nodes_attr_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('graphs.pickle', 'wb') as file:\n",
    "    pickle.dump([hero_graph, hero_comics_graph], file)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
